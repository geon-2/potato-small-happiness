export const runtime = "edge"; // ì„ íƒ: Vercel ë°°í¬ ì‹œ edge function

export async function POST(req) {
    const { input } = await req.json();

    const prompt = `
ë‹¹ì‹ ì€ ê°ì„±ì ì¸ í–‰ë³µ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸ì¥ì„ ì½ê³ , ê·¸ ì‚¬ëŒì˜ ì˜¤ëŠ˜ í–‰ë³µ ì§€ìˆ˜ë¥¼ 0~100ì ìœ¼ë¡œ ì •ìˆ˜ë¡œ íŒë‹¨í•´ ì£¼ì„¸ìš”.

ê²°ê³¼ëŠ” ì•„ë˜ì˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ, ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”:

{
  "score": 87,
  "message": "ì†Œì†Œí•˜ì§€ë§Œ í™•ì‹¤í•œ í–‰ë³µì´ì—ìš” â˜€ï¸"
}

ë¬¸ì¥: "${input}"
`;

    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST",
        headers: {
            Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
            "Content-Type": "application/json",
        },
        body: JSON.stringify({
            model: "openai/gpt-3.5-turbo",
            messages: [{ role: "user", content: prompt }],
        }),
    });

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content?.trim();

    try {
        const parsed = JSON.parse(content);
        return Response.json(parsed); // â†’ { score: 87, message: "..." }
    } catch (e) {
        return Response.json({
            score: 0,
            message: "í–‰ë³µì§€ìˆ˜ ë¶„ì„ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš” ğŸ¥²",
        });
    }
}
